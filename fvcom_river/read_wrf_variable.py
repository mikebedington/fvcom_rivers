import numpy as np
import netCDF4 as nc
import datetime as dt
from dateutil.relativedelta import relativedelta
import os
import csv


'''
Functions related to retrieving WRF output.

It expects that the wrf data will be in month netcdf files as generated by make_WRF_month_nc.sh. There should also be a netcdf with the grid info (lat, lon, lat_u, lon_u, lat_v, lat_u, all_vars), by default this is wrf_info_file.nc though it could be included in any of the month netcdfs. The path to these is provided by wrf_directory.

'''


def daterange(start_date, end_date, step):
    for n in np.arange(0,(end_date - start_date).days + 1, step):
        yield start_date + dt.timedelta(float(n))


def read_csv_dict_temp(filename):
    output = {} 

    with open(filename, 'rb') as this_file:
        this_file_data = csv.DictReader(this_file)
    
        for row in this_file_data:        
            test_row = row

        this_keys = test_row.keys()
            
        for tk in this_keys:
            this_entry = []

            with open(filename, 'rb') as this_file:
                this_file_data = csv.DictReader(this_file)
            
                for row in this_file_data:        
                    this_entry.append(row[tk])
        
            output[tk] = this_entry

    return output


def get_WRF_info(wrf_directory, *args):

    home_dir = os.getcwd()
    
    if args:
        info_file = args
    else:
        info_file = 'wrf_info_file.nc'
    
    os.chdir(wrf_directory)
    
    test_nc = nc.Dataset(info_file, 'r')
    
    output = {'XLAT': np.squeeze(test_nc.variables['XLAT'][1,:,:]), 
              'XLON': np.squeeze(test_nc.variables['XLONG'][1,:,:]), 
              'XLAT_U': np.squeeze(test_nc.variables['XLAT_U'][1,:,:]), 
              'XLON_U': np.squeeze(test_nc.variables['XLONG_U'][1,:,:]), 
              'XLAT_V': np.squeeze(test_nc.variables['XLAT_V'][1,:,:]), 
              'XLON_V': np.squeeze(test_nc.variables['XLONG_V'][1,:,:]),
              'ALL_VARS': test_nc.variables.keys()} 
    
    os.chdir(home_dir)

    return output
    

# a function to read the reduced netcdfs of only the variables of interest as generated by ncecat (using script make_WRF_month_nc.sh)
def read_WRF_year_month(this_year, this_month, wrf_directory):
    home_dir = os.getcwd()
    os.chdir(wrf_directory)
    
    data_output = {}

    full_date_list = []
    for each_date in daterange(dt.datetime(this_year,this_month,2,0,0,0), dt.datetime(this_year,this_month,1,21,0,0) + relativedelta(months=+1),0.125):
        full_date_list.append(each_date)
    
    data_output['times'] = full_date_list


    # load in the nc file which has just T2, RAINNC, and Times (as strings)
    year_nc = nc.Dataset(str(this_year) + '_' + "%02d"%this_month + '_data.nc', 'r')


    times = year_nc.variables['Times'][:]
    times_list_dt = [dt.datetime.strptime(str(b''.join(np.asarray(times)[i,:]).decode('UTF-8')),'%Y-%m-%d_%H:%M:%S') for i in range(0, len(times))]

    
    # do the temp
    data_output['T2'] = np.zeros([len(full_date_list), len(year_nc.dimensions['south_north']), len(year_nc.dimensions['west_east'])])

    temp_series = year_nc.variables['T2'][:]
    
    for this_row, this_date in enumerate(full_date_list):
        if [x for x in times_list_dt if x == this_date]:
            data_output['T2'][this_row,:,:] = [temp_series[x,:,:] for x,y in enumerate(times_list_dt) if y == this_date][0]
        else:
            data_output['T2'][this_row,:,:] = np.nan
    
    temp_series = None

    # do the rain 
    data_output['RAINNC'] = np.zeros([len(full_date_list), len(year_nc.dimensions['south_north']), len(year_nc.dimensions['west_east'])])

    rain_series = year_nc.variables['RAINNC'][:]

    for this_row, this_date in enumerate(full_date_list):
        if [x for x in times_list_dt if x == this_date]:
            data_output['RAINNC'][this_row,:,:] = [rain_series[x,:,:] for x,y in enumerate(times_list_dt) if y == this_date][0]
        else:
            data_output['RAINNC'][this_row,:,:] = np.nan
    
    rain_series = None
    
    # head back to the starting directory
    os.chdir(home_dir)
    
    # and give out the data
    return data_output

def read_WRF_year_new(this_year,  wrf_directory):

    data_output = {}
    wrf_file = '{}/wrf_summary_{}.nc'.format(wrf_directory, this_year)
    wrf_nc = nc.Dataset(wrf_file)
    
    times_raw = wrf_nc.variables['Times'][:]
    times_str = np.asarray([b''.join(this_str).decode('utf-8') for this_str in times_raw])
    times_dt = np.asarray([dt.datetime.strptime(this_str, '%Y-%m-%dT%H:%M:%S.000000') for this_str in times_str])
 
    data_output['times'] = times_dt
    data_output['T2'] = wrf_nc.variables['T2'][:]
    data_output['RAINNC'] = wrf_nc.variables['RAINNC'][:]
    
    return data_output

# Deprecated version for reading individual variables. There's a flaw in on of the C libraries for the python netCDF4 package which make doing it by loading daily files a baaaaad idea (will crash after ~ 400)
def read_WRF_var(*args, **kwargs):
    '''
    *args - the spatial request, either 'all', or a    

    **kwargs -
        'date_to_retrieve' - retrieve a single date. Should be as a string of the form e.g. '2000-01-01'
        'start_date' - retrieves between this date and a given 'end_date' will return empty if no end date specified. Dates should be a string as above
        'vars' - 

    '''    
    # grab working directory to return to at the end
    home_dir = os.getcwd() 
    
    data_output = {}
    # parse the inputs and set up the list of relevant dates and empty arrays in an output dictionary for the variables
    date_list = []
    if 'date_to_retrieve' in kwargs:
        date_list.append(dt.datetime.strptime(kwargs['date_to_retrieve'], '%Y-%m-%d'))
    
    elif 'start_date' in kwargs:
        if 'end_date' in kwargs:
            for each_date in daterange(dt.datetime.strptime(kwargs['start_date'],'%Y-%m-%d'), dt.datetime.strptime(kwargs['end_date'],'%Y-%m-%d'),1):
                date_list.append(each_date)
            
            full_date_list = []
            for each_date in daterange(dt.datetime.strptime(kwargs['start_date']+' 21:00:00','%Y-%m-%d %H:%M:%S'), dt.datetime.strptime(kwargs['end_date']+' 18:00:00','%Y-%m-%d %H:%M:%S') + dt.timedelta(days=1),0.125):
                full_date_list.append(each_date)
            
            data_output['times'] = full_date_list

        
        else:
            print('No end date specified')
            return    

    else:
        print('No dates requested')
        return 
    
    # change to correct year directory, currently only copes with one year to prevent having to change directory halfway through a loop
    if date_list[0].timetuple().tm_year == date_list[-1].timetuple().tm_year:
        if date_list[0].timetuple().tm_year == 2011: # hardcoded bodge as there are multiple physics runs for 2011
            os.chdir('/data/euryale6/scratch/pica/models/WRF/pml-uk-wrf/run/output/sst/' + str(date_list[0].timetuple().tm_year) + '_bl_pbl_physics=1/')
        else:
            os.chdir('/data/euryale6/scratch/pica/models/WRF/pml-uk-wrf/run/output/sst/' + str(date_list[0].timetuple().tm_year) + '/')
    else:
        print('Output requested across two years. Sorry nae can do pal')
        return

    # load up the first netCDF so we can get variable sizes
    test_nc = nc.Dataset('wrfout_d03_'+date_list[0].strftime('%Y-%m-%d') + '_18:00:00', 'r')
    
    if 'all' not in args:
        mesh_info = get_WRF_info()
        mesh_cat = {str(mesh_info['XLAT_V'].shape[0]) + '_' + str(mesh_info['XLAT_V'].shape[1]):[mesh_info['XLAT_V'],mesh_info['XLON_V']], 
                    str(mesh_info['XLAT_U'].shape[0]) + '_' + str(mesh_info['XLAT_U'].shape[1]):[mesh_info['XLAT_U'],mesh_info['XLON_U']], 
                    str(mesh_info['XLAT'].shape[0]) + '_' + str(mesh_info['XLAT'].shape[1]):[mesh_info['XLAT'],mesh_info['XLON']]}
        var_masks = {}


    if 'vars' in kwargs:
        for this_variable in kwargs['vars']:
            this_var_dims = test_nc.variables[this_variable].dimensions
            if len(this_var_dims)==3 and len(test_nc.dimensions[this_var_dims[0]]) == 9:                            
                if 'all' in args:                
                    data_output[this_variable] = np.zeros([8*len(date_list), len(test_nc.dimensions[this_var_dims[1]]), len(test_nc.dimensions[this_var_dims[2]])])
                elif args:
                    lat_mm = args[1]
                    lon_mm = args[2]
            
                    ll_list = mesh_cat[str(len(test_nc.dimensions[this_var_dims[1]])) +'_'+    str(len(test_nc.dimensions[this_var_dims[2]]))]                
                    
                    if 'range' in args:
                        lat_mm = args[1]
                        lon_mm = args[2]
                        var_masks[this_variable] = np.logical_and(ll_list[0] > lat_mm[0], np.logical_and(ll_list[0] < lat_mm[1], np.logical_and(ll_list[1] > lon_mm[0], ll_list[1] < lon_mm[1])))
                    elif 'points' in args:
                        # implement at some point                    
                        print('Not implement, sorry')
                        return
    
                    data_output[this_variable+'_points'] = [ll_list[0][var_masks[this_variable]], ll_list[1][var_masks[this_variable]]]  
                    data_output[this_variable] = np.zeros([8*len(date_list), sum(sum(var_masks[this_variable]))])

            
                else:
                    print('No spatial coverage specified')
                    return    
            

            elif len(this_var_dims)==3:
                print("Not 9 timesteps, this ain't built to handle that")
                return this_var_dims                
            else:
                print('Non 3-d variable requested, not built to handle that')
                return
            
    
    else:
        print('No variables requested')
        return

    
    test_nc.close()
    
    print('Retrieving WRF data')
    p_done_printer = 10
    
    # main data retrieval loop
    for this_step, this_date in enumerate(date_list):
        
        # access todays netCDF
        if os.path.isfile('wrfout_d03_'+this_date.strftime('%Y-%m-%d') + '_18:00:00'):
            this_nc = nc.Dataset('wrfout_d03_'+this_date.strftime('%Y-%m-%d') + '_18:00:00', 'r')
        
            # retrieve each variable, drop the first timestep (as is spin up step) and mask to the lat/lon requested
            # currently assumes 2d variables with 9 timesteps...should generalise at some point
            for this_variable in kwargs['vars']:
                this_output = this_nc.variables[this_variable][:]            

                if 'all' in args:
                    data_output[this_variable][this_step*8:(this_step+1)*8,:,:] = this_output[1:,:,:]
                else:
                    data_output[this_variable][this_step*8:(this_step+1)*8,:] = this_output[1:,var_masks[this_variable]]

            this_nc.close()
            
            perc_done = (this_step/float(len(date_list)))*100

            if perc_done > p_done_printer:
                print(str(p_done_printer)+'% done')
                p_done_printer = p_done_printer + 10


        else:
            print("file wrfout_d03_"+this_date.strftime('%Y-%m-%d') + "_18:00:00 doesn't exist skipping")
            
            for this_variable in kwargs['vars']:
                if 'all' in args:
                    data_output[this_variable][this_step*8:(this_step+1)*8,:,:] = np.nan 
                else:
                    data_output[this_variable][this_step*8:(this_step+1)*8,:] = np.nan

    
    # head back to the starting directory
    os.chdir(home_dir)
    
    # and give out the data
    return data_output

